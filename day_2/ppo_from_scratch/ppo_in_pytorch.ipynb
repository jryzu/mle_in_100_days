{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef771dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Implement PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb8331b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e4a7300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install swig \"gymnasium[box2d]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3310462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde51586",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1', render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5efcbc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-2.0, 2.0, (1,), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e666ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c611eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346962d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf2469a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2128432], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ad3d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     print(env.step([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3055331d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Reset the environment to generate the first observation\n",
    "# observation, info = env.reset(seed=42)\n",
    "# for _ in range(1000):\n",
    "#     # this is where you would insert your policy\n",
    "#     action = env.action_space.sample()\n",
    "\n",
    "#     # step (transition) through the environment with the action\n",
    "#     # receiving the next observation, reward and if the episode has terminateda or truncated\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#     # If the episode has ended then we can reset to start a new episode\n",
    "#     if terminated or truncated:\n",
    "#         observation, info = env.reset()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243196a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bad401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255669b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c468b6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00236187,  1.413665  , -0.23925176,  0.12199411,  0.00274366,\n",
       "         0.05419413,  0.        ,  0.        ], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afa23d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56bb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef910d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "794afa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-2.0, 2.0, (1,), float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c72a727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6759734",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_per_batch = 1000\n",
    "max_ep_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a1c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "717ad117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate one episode up to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "017fe516",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87352c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14995256,  0.9886932 , -0.12224312], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9b66e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2717af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f11ae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9419495], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe031d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82ecd79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b61698ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6169557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation, info = env.reset(seed=42)\n",
    "# for _ in range(1000):\n",
    "#     # this is where you would insert your policy\n",
    "#     action = env.action_space.sample()\n",
    "\n",
    "#     # step (transition) through the environment with the action\n",
    "#     # receiving the next observation, reward and if the episode has terminateda or truncated\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#     # If the episode has ended then we can reset to start a new episode\n",
    "#     if terminated or truncated:\n",
    "#         observation, info = env.reset()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3d1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dac733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0020e7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1730d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a871ddc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PPO: # asked ChatGPT to give me the class skeleton\n",
    "    def __init__(self, policy_cls, env):\n",
    "        self.obs_dim = env.observation_space.shape[0]\n",
    "        self.act_dim = env.action_space.shape[0]\n",
    "        self.actor = policy_cls(self.obs_dim, self.act_dim)\n",
    "        self.critic = policy_cls(self.obs_dim, 1) # for the reward\n",
    "        self.cov_mat = torch.eye(env.action_space.shape[0])\n",
    "        self.max_timesteps = 200\n",
    "        \n",
    "    def get_action(self, obs):\n",
    "        mean = self.actor.forward(torch.tensor(obs))\n",
    "        dist = MultivariateNormal(mean, self.cov_mat)\n",
    "        action = dist.sample()\n",
    "        return dist.sample(), dist.log_prob(action)\n",
    "    \n",
    "    def rollout(self, timesteps_per_batch):\n",
    "        batch_obs = []\n",
    "        batch_acts = []\n",
    "        batch_log_probs = []\n",
    "        \n",
    "        batch_lens = []\n",
    "        batch_rews = []\n",
    "        batch_rtgs = []\n",
    "        collected = 0\n",
    "        \n",
    "        while collected < timesteps_per_batch:\n",
    "            print(datetime.datetime.now())\n",
    "            print(collected)\n",
    "            ep_t = 0 \n",
    "            ep_rews = []\n",
    "            obs, _ = env.reset()\n",
    "            terminated, truncated = False, False\n",
    "            while not terminated and not truncated and ep_t < self.max_timesteps:\n",
    "                act, log_prob = self.get_action(obs)\n",
    "                obs, rew, terminated, truncated, _ = env.step(act)\n",
    "                batch_obs.append(obs)\n",
    "                batch_acts.append(act)\n",
    "                batch_log_probs.append(log_prob)\n",
    "#                 rtgs = # consulted \n",
    "#                 batch_lens = \n",
    "                ep_t += 1\n",
    "                ep_rews.append(rew)\n",
    "                collected += 1\n",
    "            batch_lens.append(ep_t + 1)\n",
    "            batch_rews.append(ep_rews)\n",
    "            \n",
    "        batch_obs = torch.tensor(batch_obs, dtype=torch.float)\n",
    "        batch_acts = torch.tensor(batch_acts, dtype=torch.float)\n",
    "        batch_log_probs = torch.tensor(batch_log_probs, dtype=torch.float)\n",
    "        batch_rtgs = self.compute_rtgs(batch_rews)\n",
    "        \n",
    "        return batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens\n",
    "            \n",
    "    @staticmethod # learned something new here\n",
    "    def compute_rtgs(batch_rews, gamma): # consulted ChatGPT\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "#     def learn(self, env, n_timesteps = 1000):\n",
    "#         for t in range(n_timesteps):\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "72005323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a75501c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(FeedForwardNN, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ff7624bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e98bf6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.3715]), tensor(-1.0040, grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_action(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8105f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 22:01:09.888966\n",
      "0\n",
      "2025-06-03 22:01:16.708343\n",
      "200\n",
      "2025-06-03 22:01:23.516078\n",
      "400\n",
      "2025-06-03 22:01:30.336312\n",
      "600\n",
      "2025-06-03 22:01:37.160041\n",
      "800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1647, -0.9863, -0.4069],\n",
       "         [-0.2210, -0.9753, -1.1479],\n",
       "         [-0.3102, -0.9507, -1.8509],\n",
       "         ...,\n",
       "         [-0.1353, -0.9908, -1.6518],\n",
       "         [-0.2495, -0.9684, -2.3291],\n",
       "         [-0.3943, -0.9190, -3.0615]]),\n",
       " tensor([-2.9076e-02, -8.3482e-03,  1.8953e-01, -1.3003e+00, -5.9516e-01,\n",
       "         -4.5322e-02,  2.2490e+00, -9.2591e-01, -1.2165e+00,  8.3836e-01,\n",
       "          4.3991e-02,  2.8383e-01,  8.5482e-01,  5.2608e-01,  5.6938e-01,\n",
       "          7.4281e-01,  2.1864e-01,  8.6609e-01, -5.5831e-01, -1.7975e+00,\n",
       "          3.7256e-01, -1.8093e+00,  1.8011e+00,  4.2690e-01,  2.0764e-01,\n",
       "          3.0229e-01, -3.9420e-01,  9.4598e-02,  6.5420e-01, -7.0653e-01,\n",
       "         -3.1216e-01,  1.5456e+00, -4.0357e-01,  9.7965e-01, -7.7600e-01,\n",
       "         -1.7789e+00, -1.8941e+00,  2.9155e-01, -2.4498e-03,  7.2697e-01,\n",
       "         -2.4961e-01,  1.9850e+00, -1.5172e-01, -9.7602e-01, -1.0015e+00,\n",
       "         -2.7496e-01,  1.1058e+00, -5.6173e-01, -1.6438e+00, -3.0378e-01,\n",
       "         -5.8729e-01,  7.0013e-01, -5.9141e-01, -1.0816e+00,  2.4404e+00,\n",
       "         -1.2600e+00, -4.9101e-01, -5.0720e-01,  8.1729e-02,  1.0804e+00,\n",
       "         -6.5589e-03,  2.1236e-01, -2.8488e-01,  1.4733e+00,  2.5255e-01,\n",
       "         -1.2600e+00, -1.4541e+00, -4.6977e-02, -8.1122e-01,  4.2088e-02,\n",
       "         -5.4026e-02, -2.1696e+00, -1.9982e-02,  1.7747e+00,  1.0970e-01,\n",
       "          8.7059e-01,  2.5382e+00,  4.6127e-01, -1.5731e+00, -3.5379e-02,\n",
       "         -1.2179e-01, -1.3661e+00, -1.2059e+00, -1.6240e+00, -2.7966e-01,\n",
       "          2.2313e-01,  1.9053e+00,  1.9058e+00, -1.9126e+00,  2.1681e+00,\n",
       "         -1.7717e+00, -2.5203e-03,  6.6535e-01,  9.3080e-01, -1.0381e+00,\n",
       "          1.5134e+00, -4.7357e-01, -1.4279e-01,  1.3970e+00, -1.0859e-01,\n",
       "         -1.7231e+00,  1.6221e+00, -1.2503e+00, -1.0284e-01, -1.0485e+00,\n",
       "          1.4270e-01, -6.7486e-01,  7.1296e-01, -3.2883e-01,  6.2273e-03,\n",
       "          1.2926e-01,  4.3258e-01, -4.2792e-01, -6.3289e-01, -8.1618e-01,\n",
       "         -8.5320e-01, -1.6701e+00,  1.4503e+00,  8.7985e-02,  1.7659e+00,\n",
       "         -1.0472e+00,  1.9072e+00,  3.6466e-01, -2.4287e-01,  5.2222e-01,\n",
       "         -1.0937e+00, -6.5430e-01, -8.3638e-01, -3.4810e-01,  9.0412e-01,\n",
       "          3.6588e-01,  8.6474e-01, -1.8286e-01, -1.3292e+00,  1.0553e-01,\n",
       "          5.5690e-01, -1.2687e-03,  1.0410e-01, -1.6014e+00,  7.0269e-01,\n",
       "         -2.9683e-01, -1.5534e+00,  8.6597e-01, -1.3149e+00, -8.0381e-01,\n",
       "         -5.1291e-01, -7.7204e-01, -2.2220e+00, -1.5868e-01,  1.1027e+00,\n",
       "          4.4621e-02, -9.8771e-02, -6.7277e-02, -4.8756e-01,  5.0879e-01,\n",
       "          7.7306e-01,  5.8757e-01,  4.3574e-01, -2.7261e+00,  1.1398e+00,\n",
       "         -1.3196e+00, -7.5062e-01,  4.3905e-01,  1.3628e+00,  2.0323e+00,\n",
       "         -2.5613e-01, -7.8036e-01, -2.0223e+00,  2.6104e+00,  2.6096e-01,\n",
       "          1.1037e+00,  1.3668e+00, -6.6240e-01,  2.4787e+00,  7.4965e-02,\n",
       "          1.4162e+00,  2.6664e+00, -1.9247e+00, -1.4424e-01, -8.6027e-01,\n",
       "          6.6680e-01,  6.0205e-02,  1.0415e+00,  8.1467e-01,  4.1789e-02,\n",
       "         -1.1981e-01,  4.8977e-01, -8.4247e-01, -1.7295e-01,  1.0891e-01,\n",
       "         -3.2254e-02, -8.0917e-01, -1.0911e+00, -9.5358e-02,  1.0610e+00,\n",
       "          4.8028e-01, -5.7681e-01, -1.9100e-01,  4.0817e-01,  1.8360e-02,\n",
       "          7.5073e-02,  8.1558e-01, -1.1377e+00,  6.0788e-01, -4.2844e-01,\n",
       "         -1.0141e+00,  8.9550e-01, -1.0249e+00,  8.3111e-01,  6.5117e-01,\n",
       "         -1.2418e-01, -1.0788e+00, -7.3693e-02, -1.3614e-01,  1.7984e+00,\n",
       "          1.1025e+00,  6.6278e-01,  5.8114e-01, -1.0056e-01,  1.4809e+00,\n",
       "         -9.5881e-01, -7.5361e-01,  7.6637e-01,  2.1119e+00, -6.7274e-01,\n",
       "          1.8628e-01, -2.6957e-01,  4.8193e-01,  5.5858e-01,  1.1405e+00,\n",
       "         -5.7374e-01, -2.6734e-01, -2.4645e-01, -7.9624e-02, -7.0553e-01,\n",
       "         -4.6389e-02,  4.8169e-01,  2.0318e-01, -4.1761e-01, -8.1600e-01,\n",
       "         -9.2634e-01, -5.2950e-01,  2.3696e-01, -3.4180e-01, -8.2949e-01,\n",
       "         -5.6816e-01,  3.1562e-01,  4.6790e-01,  1.2467e+00, -7.6382e-01,\n",
       "          3.1522e-01,  6.6782e-01, -1.3477e+00,  1.7798e+00,  6.1113e-01,\n",
       "          2.0450e-01, -2.7022e+00, -1.9350e-01, -3.5516e-02,  1.3522e+00,\n",
       "          8.6823e-02, -1.5736e+00,  7.4924e-01, -2.2452e-01,  6.4763e-01,\n",
       "         -1.1426e+00,  3.1325e-01, -6.3010e-01,  1.3186e+00, -7.0698e-01,\n",
       "         -8.4821e-01, -1.7131e-01,  2.3249e-01, -1.1339e-01,  1.0075e+00,\n",
       "         -7.6306e-02, -1.4479e+00, -6.3666e-01,  2.0078e+00,  6.7326e-01,\n",
       "          1.0032e+00,  9.7784e-01, -1.3151e-01, -8.7836e-02,  2.5844e+00,\n",
       "          1.3252e+00,  8.7295e-01, -6.5838e-01,  8.7388e-01, -1.0100e-02,\n",
       "          7.5683e-01, -2.1910e+00, -2.0269e-01,  1.2770e-01, -2.5832e-01,\n",
       "         -1.3500e+00, -7.4197e-01,  1.3352e-01, -1.4768e+00, -5.1091e-02,\n",
       "          3.1929e+00, -1.1904e-01,  8.0595e-01,  1.3631e+00, -4.0868e-01,\n",
       "         -6.3354e-01, -9.4220e-01, -1.3776e+00,  5.1902e-01, -2.7000e-01,\n",
       "         -2.3358e-01,  8.0608e-01, -9.7654e-01,  1.8810e+00,  2.1500e+00,\n",
       "         -4.2080e-01, -6.7873e-01,  6.2686e-01, -2.7566e+00, -1.5436e-01,\n",
       "         -4.6244e-01,  1.4977e+00,  4.4904e-01,  8.4398e-01, -1.0535e+00,\n",
       "          1.3244e+00,  1.5313e+00,  3.9331e-01, -5.8325e-01,  7.2828e-01,\n",
       "         -3.5955e-01, -1.1322e+00,  8.4010e-01, -7.0406e-01,  9.8567e-01,\n",
       "         -1.1429e+00,  3.2049e-01,  3.0718e-01,  3.9096e-01,  4.5576e-01,\n",
       "         -2.0682e+00,  1.5402e+00, -4.1109e-01, -4.8825e-01, -1.0553e+00,\n",
       "          1.1418e+00,  4.0872e-01,  1.5484e+00,  2.3992e-01, -5.9951e-01,\n",
       "          7.2350e-01,  7.8967e-01, -1.3031e+00,  1.0029e+00, -6.3218e-01,\n",
       "          4.0572e-01, -3.3154e-01, -3.6287e-01,  1.2478e+00, -1.5520e+00,\n",
       "         -3.5823e-01, -7.7966e-02,  9.2002e-01,  1.5654e+00, -1.1964e+00,\n",
       "         -9.3877e-01,  3.6481e-01, -2.6576e-02, -8.3114e-01, -6.8345e-01,\n",
       "          1.0579e+00,  5.4197e-01,  4.4122e-01, -1.1905e+00, -2.1651e-01,\n",
       "         -1.3568e+00, -1.7768e-01,  8.3819e-02,  1.1519e+00, -7.1284e-01,\n",
       "         -1.8963e+00,  1.5434e+00,  1.6409e+00,  4.1240e-01,  1.0907e+00,\n",
       "         -7.9047e-01,  1.3954e+00,  3.9295e-01, -8.7193e-01,  5.3281e-02,\n",
       "          6.1642e-01, -1.2669e+00, -3.0659e-01,  6.2732e-01,  9.3822e-01,\n",
       "         -2.5893e-01,  2.8454e-01,  5.7058e-01,  1.3468e-01, -3.4736e-01,\n",
       "         -1.3796e+00,  1.5184e-01, -6.8982e-01, -1.0782e+00,  5.9205e-02,\n",
       "         -4.4975e-02, -2.9559e+00,  1.0794e+00, -3.7590e-01, -3.4618e-01,\n",
       "          1.9034e-01, -1.0876e-01, -6.1307e-01,  1.1485e+00,  2.8692e-02,\n",
       "         -1.0455e+00, -7.6509e-01, -1.5602e+00,  2.6043e-01,  1.5129e+00,\n",
       "         -1.7002e+00,  1.5916e+00,  1.0666e+00, -7.5375e-01,  9.0957e-01,\n",
       "          2.0576e+00, -1.0480e+00, -1.9990e-01, -8.3771e-01, -9.8711e-01,\n",
       "         -2.3244e+00, -6.2356e-01,  7.4232e-01,  8.2791e-01,  4.9902e-01,\n",
       "         -4.1163e-01,  3.4514e-02,  9.5379e-01,  1.2359e+00,  1.9488e-01,\n",
       "          6.6931e-01,  1.2986e+00,  1.0849e-01,  1.6223e-01, -2.9630e-01,\n",
       "         -1.1275e+00,  1.4444e-01, -9.9638e-01,  1.9850e+00, -8.6919e-01,\n",
       "          2.7856e-01, -6.0262e-01,  4.6016e-01, -1.6759e+00,  8.2242e-01,\n",
       "         -8.4388e-01, -4.6971e-01, -9.6585e-02, -5.2507e-01, -5.3714e-01,\n",
       "          8.2815e-01,  8.2777e-01,  8.9122e-02, -9.4779e-01, -1.9416e+00,\n",
       "         -2.5475e+00, -5.5773e-01,  2.9457e-01, -8.9392e-01, -6.6632e-01,\n",
       "          1.8612e-01,  1.2268e+00,  1.8875e-01,  3.9860e-01,  1.0682e+00,\n",
       "          2.5022e-01, -1.0446e+00, -9.4282e-01, -6.9397e-01, -1.6368e+00,\n",
       "          1.4175e+00,  1.3096e+00,  1.2173e+00,  2.9859e-01, -1.0216e-01,\n",
       "         -3.9922e-02,  1.5493e+00,  9.1189e-01, -8.8855e-01,  3.3992e-01,\n",
       "         -8.3703e-01,  1.2144e-01,  9.8699e-01,  3.8525e-01, -1.6119e+00,\n",
       "         -4.3929e-01, -6.1647e-01, -8.2306e-01,  1.8912e-01,  6.8844e-02,\n",
       "         -7.0779e-01,  1.4369e-01, -1.8273e+00,  1.8037e+00,  1.1273e+00,\n",
       "         -3.4232e-01, -2.2183e-01, -1.9364e+00, -1.4573e+00, -9.7822e-01,\n",
       "          6.9473e-01,  9.2486e-01,  2.4392e-01, -5.1060e-01,  2.1510e-01,\n",
       "          1.1049e-01,  7.1298e-01,  3.3389e-01,  1.2182e+00, -1.3214e-01,\n",
       "          2.3241e+00, -4.9880e-01,  3.6687e-01, -5.4354e-02,  9.6846e-03,\n",
       "          1.1039e+00,  1.1910e+00,  1.3529e-01, -9.7462e-01,  4.2025e-01,\n",
       "          2.8387e-01, -4.4418e-01,  5.2789e-01, -4.2470e-01, -3.3142e-02,\n",
       "         -6.0421e-01, -1.6548e+00,  1.9202e-01, -1.5094e+00,  1.3948e+00,\n",
       "         -5.8160e-01,  2.4808e-02,  1.0207e+00,  7.0042e-01, -8.6422e-01,\n",
       "         -4.2888e-01,  2.3515e+00, -3.3245e-01, -1.4142e+00, -1.2207e+00,\n",
       "          1.7547e+00, -9.1090e-01,  9.0987e-02,  7.9366e-01,  2.4412e-01,\n",
       "          9.1229e-01,  1.6833e-01, -3.7182e-04, -1.2071e+00, -1.8311e-01,\n",
       "          8.8222e-01,  1.9999e+00, -1.3643e+00,  9.3074e-02,  1.8067e+00,\n",
       "          3.7843e-02, -2.1727e+00,  4.3892e-01,  1.0672e+00,  1.1000e+00,\n",
       "          1.3711e-01,  4.4155e-01, -1.1810e+00,  1.5249e+00, -8.2982e-01,\n",
       "         -4.8061e-01, -3.2724e+00, -2.1579e-01, -5.3977e-02, -2.6567e-01,\n",
       "         -7.2455e-01, -1.6583e-01,  5.4149e-01,  6.2812e-01, -3.8810e-01,\n",
       "          7.3347e-01,  4.0439e-01,  2.1982e-01, -1.4156e-01,  6.9613e-01,\n",
       "          6.9748e-01, -2.0796e-01,  7.6226e-02,  4.8803e-01, -8.1438e-01,\n",
       "          7.4802e-01, -1.2515e-01, -1.1816e-01, -7.9604e-01,  1.4955e+00,\n",
       "          8.1219e-01, -2.3478e-01,  1.6430e+00,  2.2208e-01,  2.4863e-01,\n",
       "          1.2265e-01,  5.4960e-02,  1.7754e+00,  4.2845e-01,  1.7343e+00,\n",
       "         -4.3004e-01,  1.8115e+00, -2.2731e+00,  1.1027e-01, -1.0996e-01,\n",
       "          1.2954e+00, -9.2722e-01, -1.7640e+00, -8.9628e-01,  5.4056e-01,\n",
       "          2.1204e-01,  8.3299e-01, -2.6832e-01,  2.1197e-01,  2.7216e-01,\n",
       "         -5.0673e-01, -6.1545e-01, -2.0913e-01,  6.9995e-01, -1.2660e+00,\n",
       "         -5.8730e-01,  2.1158e-01, -2.3099e+00,  1.0573e+00, -2.1687e+00,\n",
       "          1.4061e+00,  1.0026e+00,  9.3101e-01,  1.0451e+00,  6.4921e-01,\n",
       "         -7.9951e-01, -9.6715e-01, -9.9743e-01,  3.1372e-01,  5.0784e-01,\n",
       "         -3.4953e-01,  8.0602e-01, -1.3913e-02,  5.3144e-01,  1.4777e+00,\n",
       "         -1.0743e+00, -2.3117e+00, -9.4334e-01,  1.2408e+00, -5.1857e-01,\n",
       "          1.4223e+00,  4.3391e-01, -1.1754e+00,  4.1128e-01,  2.7417e-01,\n",
       "         -3.2353e-01,  1.1872e+00,  3.3531e-01,  2.2310e-01, -1.1615e+00,\n",
       "          7.9345e-01, -8.8413e-01, -7.6489e-01,  1.8682e+00,  3.3170e-01,\n",
       "          1.1112e+00,  4.1608e-01,  1.1763e+00,  1.2276e+00,  9.0222e-01,\n",
       "         -1.5504e+00, -5.1939e-01,  3.8056e-01,  1.4782e-01,  2.3334e-01,\n",
       "          2.9124e-01,  7.4155e-02, -4.0261e-01, -6.8219e-01,  2.2753e+00,\n",
       "          6.5985e-01,  1.0126e+00, -1.1896e+00, -1.4868e+00, -1.6672e+00,\n",
       "         -1.2431e+00, -6.9239e-01, -1.1774e+00, -2.2917e-01, -6.5880e-01,\n",
       "         -4.7920e-01,  6.4263e-01,  1.3114e+00, -1.3104e+00,  2.0403e-01,\n",
       "         -6.5609e-01,  2.1284e+00, -7.2923e-01,  6.8438e-01, -5.0433e-01,\n",
       "         -1.2398e+00, -5.2237e-03, -8.3162e-01,  9.2210e-02,  5.7350e-01,\n",
       "          1.1338e+00,  7.9598e-01,  3.7944e-01,  1.2005e+00,  7.5602e-01,\n",
       "         -6.4645e-01, -1.3690e+00,  8.0233e-01, -5.2759e-01, -3.1205e-01,\n",
       "         -5.9719e-01, -1.1608e+00,  2.0529e+00, -6.4633e-01,  7.8840e-02,\n",
       "          4.9701e-01,  5.0909e-01,  4.9811e-01, -2.4539e-01, -2.4308e-01,\n",
       "         -2.8578e+00,  6.7709e-01,  2.1752e+00,  1.0796e+00, -9.3658e-01,\n",
       "          1.4612e+00,  4.6978e-01,  1.3576e-01,  1.3716e+00, -6.2177e-01,\n",
       "         -1.8934e-01, -2.6968e-01,  1.1703e+00,  1.7493e+00,  4.4377e-01,\n",
       "          2.2586e-01, -7.6162e-01, -3.3273e-01,  7.6116e-01, -1.3902e+00,\n",
       "         -1.7927e+00,  7.1338e-01,  2.2998e+00,  8.6199e-01, -1.4500e+00,\n",
       "         -1.0744e+00, -1.6255e-01,  1.7521e+00,  2.6594e-01, -3.2802e-01,\n",
       "         -1.4408e+00,  1.4592e-01,  8.9516e-01, -2.3427e+00, -6.3285e-01,\n",
       "         -1.2297e+00,  1.0500e+00,  8.7225e-01, -8.0764e-01,  2.8386e-01,\n",
       "         -8.4885e-01, -5.2841e-01,  2.7344e-01,  1.5316e+00,  1.5135e+00,\n",
       "          2.5340e-01, -2.8614e-01, -1.3469e+00,  1.1407e+00,  7.4052e-01,\n",
       "          8.5598e-01, -1.7224e-01,  1.5994e-02, -2.2332e-01, -2.6927e-01,\n",
       "         -5.6882e-01, -2.4201e-01,  1.0922e+00, -1.1861e+00,  3.1182e-02,\n",
       "         -3.1937e-01,  2.0092e+00,  4.4896e-01,  7.5292e-01, -2.2759e+00,\n",
       "          9.4294e-01, -5.3249e-01, -1.0116e+00, -7.4006e-01, -4.7149e-03,\n",
       "          1.2651e+00,  8.4922e-01,  1.2033e+00, -1.9935e-01,  7.3760e-01,\n",
       "          3.2788e-02,  6.6037e-01,  3.0573e-01,  2.3033e-01,  4.3403e-01,\n",
       "          2.3495e-01, -1.6607e+00, -5.3357e-01,  1.4048e-01, -4.1140e-01,\n",
       "          1.7402e+00,  6.3710e-01,  2.3198e-01, -1.7321e+00,  1.6984e+00,\n",
       "          9.5094e-01, -2.0892e+00,  4.6992e-02, -7.9814e-01,  1.8409e+00,\n",
       "          7.9173e-01,  1.4243e+00,  8.1499e-01,  1.4960e+00, -9.6356e-01,\n",
       "         -4.6837e-02,  5.4184e-01, -1.5995e+00,  1.0849e+00, -1.4272e+00,\n",
       "          1.2422e+00,  6.6012e-01, -1.0109e+00,  6.4760e-01, -2.9007e-01,\n",
       "          1.7670e+00,  6.0115e-02, -9.7974e-01,  1.4159e-01, -6.0824e-01,\n",
       "          1.0823e+00, -9.3406e-01,  3.5951e-02, -1.0306e-03,  4.8474e-01,\n",
       "         -1.0893e+00,  8.9156e-01, -8.2241e-01,  4.1246e-01, -9.4069e-01,\n",
       "         -1.5406e+00,  1.7868e+00,  1.4843e+00, -2.8348e-01,  6.9383e-01,\n",
       "         -8.1092e-01, -8.4096e-01,  1.0019e-01, -4.9591e-01,  5.3266e-01,\n",
       "          5.7036e-01,  3.9496e-01,  3.5497e-01, -3.9435e-01, -7.7966e-01,\n",
       "          3.3648e-01,  5.5737e-01,  1.1178e+00, -9.4953e-01,  5.4176e-01,\n",
       "         -1.0627e+00, -1.6637e+00,  8.4158e-01,  3.1196e-01, -5.4505e-01,\n",
       "          4.5981e-01, -5.3896e-01, -1.3478e+00, -1.2102e+00,  7.3202e-01,\n",
       "          2.3304e+00,  2.1689e-01, -7.4578e-01,  1.8113e+00, -3.3632e-01,\n",
       "         -3.0344e-01, -5.9381e-01,  5.7840e-01,  1.8642e+00, -3.3318e-02,\n",
       "          1.0652e-01, -1.1301e+00, -9.4720e-01,  1.4916e+00,  4.8777e-01,\n",
       "         -8.1095e-01,  4.9523e-01,  5.0025e-01, -1.2175e+00, -1.5255e+00,\n",
       "         -2.2656e-01,  5.0812e-01, -1.0684e+00,  6.6453e-02, -1.0540e+00,\n",
       "          2.3457e-01,  7.3944e-01,  9.8250e-01, -2.1481e+00,  7.6928e-01,\n",
       "         -2.2102e-01,  4.7807e-01, -8.0728e-02,  1.5752e-01,  7.6424e-02,\n",
       "          1.7465e+00,  9.5279e-02, -1.6577e+00,  1.0271e+00, -5.8450e-01,\n",
       "         -2.3171e-01, -5.0488e-01, -9.6282e-01, -3.7018e-01,  3.7514e-01,\n",
       "          6.8859e-01, -8.4725e-01, -4.4973e-01,  6.7335e-01,  8.5322e-01,\n",
       "         -7.7712e-01,  2.7895e-01, -4.0529e-01, -1.4535e+00, -2.2495e-01,\n",
       "          7.9723e-01, -5.4044e-01, -2.1451e-01,  6.8607e-02, -4.8268e-01,\n",
       "         -2.1467e-01, -2.1242e+00, -1.2712e+00, -1.6426e+00, -1.2591e+00,\n",
       "         -1.8951e+00, -1.4150e+00,  7.4320e-01,  6.8301e-01, -2.1223e-01,\n",
       "          1.9100e+00,  4.7248e-01, -1.5725e-01,  2.7370e-01,  1.3420e+00,\n",
       "          1.2110e+00, -3.0759e-02, -3.2248e-02, -6.8221e-01, -6.1145e-01,\n",
       "          6.3224e-01,  2.0271e+00, -8.2692e-01,  1.3000e-01,  9.8471e-01,\n",
       "         -9.7576e-01,  1.1721e+00, -1.6315e-01, -9.2655e-01, -1.0608e+00,\n",
       "          6.7764e-01, -1.9611e+00,  1.6268e+00, -9.5949e-01,  3.1877e-01,\n",
       "          1.0289e+00, -9.0206e-03, -1.6647e-01, -2.5152e+00,  6.9487e-01,\n",
       "         -9.2513e-01, -2.7124e-01,  3.0833e-01, -1.3595e+00, -9.3294e-01,\n",
       "         -7.3528e-02,  8.3228e-01,  7.0734e-01,  2.0488e+00, -2.4212e+00,\n",
       "         -1.0346e+00, -5.4235e-01,  8.6476e-01,  4.3863e-01, -4.1196e-02]),\n",
       " tensor([-0.9205, -0.9541, -1.9340, -1.1244, -1.0730, -0.9198, -1.9368, -2.5547,\n",
       "         -4.5158, -1.0201, -1.1153, -1.0395, -0.9891, -1.2713, -2.3080, -1.0868,\n",
       "         -1.5175, -0.9190, -1.5779, -0.9265, -3.0018, -1.1729, -1.0304, -1.0490,\n",
       "         -1.9196, -0.9418, -0.9511, -1.3090, -0.9252, -1.2483, -1.9035, -1.5461,\n",
       "         -1.6468, -0.9810, -0.9236, -1.0109, -0.9220, -3.4717, -2.1246, -0.9354,\n",
       "         -0.9412, -0.9938, -1.2132, -2.3696, -0.9390, -2.4913, -1.4037, -1.0269,\n",
       "         -1.1436, -1.5606, -0.9261, -1.1974, -1.4147, -0.9843, -1.7577, -1.3576,\n",
       "         -3.2433, -0.9967, -0.9316, -3.1827, -0.9714, -0.9195, -1.7975, -0.9460,\n",
       "         -0.9321, -1.3145, -1.0343, -0.9263, -1.0332, -2.3578, -1.0246, -0.9956,\n",
       "         -1.3401, -0.9408, -1.6100, -2.0570, -0.9189, -1.0795, -1.3621, -1.0267,\n",
       "         -1.1344, -1.1011, -0.9284, -1.2800, -0.9201, -1.8166, -1.1705, -1.2876,\n",
       "         -1.0465, -1.4485, -0.9923, -0.9454, -1.0752, -1.0590, -1.4705, -0.9237,\n",
       "         -1.1592, -1.5516, -1.6667, -0.9342, -1.2610, -1.1906, -4.7409, -0.9967,\n",
       "         -0.9252, -2.2155, -1.1766, -0.9967, -0.9257, -1.1845, -1.4189, -1.1445,\n",
       "         -1.6108, -1.2748, -1.1355, -1.5461, -1.2906, -2.4840, -1.2036, -2.1611,\n",
       "         -1.7192, -1.1017, -3.1934, -1.0405, -1.7298, -1.0725, -1.7979, -1.4943,\n",
       "         -4.7267, -1.4733, -1.0487, -1.0363, -1.1921, -1.3371, -0.9563, -0.9221,\n",
       "         -1.4218, -0.9410, -2.5601, -1.2433, -1.1806, -1.8208, -1.0189, -1.4768,\n",
       "         -1.6557, -0.9216, -1.1253, -1.1123, -1.0800, -1.8300, -2.6212, -1.2677,\n",
       "         -0.9599, -1.7474, -3.3481, -0.9764, -0.9891, -0.9948, -1.0050, -1.9560,\n",
       "         -4.4679, -1.8732, -1.1886, -1.1303, -2.0343, -1.6661, -0.9791, -0.9715,\n",
       "         -0.9597, -1.0211, -1.0534, -1.0347, -1.2597, -2.5921, -0.9633, -2.3294,\n",
       "         -1.0376, -1.6128, -1.3860, -1.2996, -0.9750, -1.4236, -0.9526, -1.1508,\n",
       "         -1.2149, -2.2394, -1.3909, -2.0351, -0.9957, -2.4190, -3.1306, -0.9430,\n",
       "         -1.0060, -1.1577, -2.7042, -0.9877, -1.4027, -0.9736, -1.6077, -0.9233,\n",
       "         -0.9189, -0.9389, -0.9202, -1.2462, -1.1320, -1.0413, -1.2459, -0.9412,\n",
       "         -1.4419, -1.3643, -1.6138, -1.1294, -1.7079, -0.9546, -0.9281, -0.9511,\n",
       "         -0.9309, -3.2485, -1.1010, -1.8393, -1.5609, -0.9809, -1.0366, -1.2711,\n",
       "         -0.9843, -0.9540, -1.4207, -0.9729, -1.1026, -0.9277, -1.4361, -1.3557,\n",
       "         -1.8033, -0.9189, -1.7605, -0.9836, -0.9921, -1.4122, -1.7913, -1.2621,\n",
       "         -1.3126, -0.9377, -1.8458, -1.0017, -1.3176, -1.1106, -1.0287, -1.4979,\n",
       "         -2.1898, -1.0036, -1.2426, -1.0913, -3.4757, -0.9740, -1.1604, -1.0053,\n",
       "         -0.9792, -0.9335, -2.9319, -0.9275, -1.3666, -1.0895, -0.9443, -1.5035,\n",
       "         -0.9454, -0.9434, -1.1327, -0.9195, -0.9671, -1.4503, -0.9363, -0.9423,\n",
       "         -0.9485, -1.5012, -2.4645, -0.9434, -3.3778, -0.9425, -0.9201, -5.0662,\n",
       "         -1.0395, -1.6730, -0.9220, -1.0781, -0.9375, -0.9532, -0.9309, -1.0521,\n",
       "         -1.9549, -0.9925, -0.9744, -1.2444, -0.9873, -1.3681, -1.2764, -2.6978,\n",
       "         -0.9246, -1.5909, -1.4773, -1.2225, -0.9204, -1.0418, -1.6410, -1.6724,\n",
       "         -1.4042, -0.9261, -1.4247, -0.9330, -0.9649, -0.9320, -1.0428, -1.2934,\n",
       "         -2.2268, -4.1763, -0.9225, -0.9357, -0.9195, -1.0051, -1.4838, -0.9358,\n",
       "         -0.9315, -0.9318, -0.9841, -1.5891, -1.1785, -0.9491, -0.9378, -1.3626,\n",
       "         -1.0069, -1.7901, -1.1375, -0.9845, -0.9643, -1.2821, -0.9346, -2.8723,\n",
       "         -1.3931, -0.9860, -1.6506, -1.9767, -0.9479, -1.7141, -1.2001, -0.9737,\n",
       "         -5.2747, -0.9770, -1.2854, -1.5652, -0.9272, -1.0218, -1.1390, -2.2344,\n",
       "         -1.2062, -1.1675, -1.0654, -0.9589, -1.3330, -1.0677, -0.9685, -0.9193,\n",
       "         -0.9438, -0.9283, -1.2259, -2.0888, -1.1902, -1.2599, -1.0373, -1.0645,\n",
       "         -1.4607, -0.9233, -1.0444, -1.2115, -0.9525, -0.9192, -2.2676, -1.0075,\n",
       "         -0.9542, -1.0502, -2.3745, -1.3949, -1.6844, -1.3604, -0.9499, -1.4412,\n",
       "         -1.3643, -1.7102, -0.9687, -1.2487, -1.1503, -1.2366, -0.9208, -1.1445,\n",
       "         -1.0420, -1.0534, -1.0033, -0.9363, -1.0906, -2.3040, -1.0301, -1.4214,\n",
       "         -2.4731, -2.0276, -0.9322, -2.4777, -0.9248, -0.9255, -0.9316, -0.9943,\n",
       "         -0.9381, -0.9196, -5.1388, -0.9774, -1.8766, -0.9244, -0.9289, -1.2651,\n",
       "         -1.0037, -0.9913, -2.2021, -0.9199, -0.9398, -3.5473, -1.1535, -0.9190,\n",
       "         -0.9343, -0.9316, -0.9252, -2.0521, -0.9982, -0.9193, -1.1089, -1.6719,\n",
       "         -1.0083, -0.9561, -0.9436, -0.9273, -2.3294, -1.4618, -2.5085, -0.9305,\n",
       "         -1.0670, -2.1068, -0.9377, -1.7011, -1.3031, -1.6039, -0.9856, -0.9660,\n",
       "         -2.2366, -0.9294, -0.9642, -3.8631, -1.1069, -0.9260, -2.0989, -0.9267,\n",
       "         -1.4796, -0.9648, -0.9344, -0.9198, -0.9196, -0.9191, -0.9330, -1.2395,\n",
       "         -3.2080, -1.5837, -1.2720, -0.9808, -3.0288, -1.3066, -1.1742, -1.0322,\n",
       "         -3.2954, -1.9744, -0.9195, -5.0745, -2.6034, -3.6611, -1.1001, -1.1866,\n",
       "         -0.9732, -1.3160, -0.9712, -0.9236, -0.9213, -1.5730, -0.9430, -1.8155,\n",
       "         -2.5078, -0.9533, -0.9263, -0.9234, -0.9284, -1.6270, -1.6258, -1.4349,\n",
       "         -1.2818, -2.1270, -1.0953, -1.0644, -1.5442, -1.1194, -0.9275, -0.9408,\n",
       "         -1.4515, -1.1361, -1.7319, -2.8060, -1.0311, -2.6475, -0.9227, -1.1638,\n",
       "         -1.0504, -1.2458, -2.6682, -1.1364, -1.0080, -1.5343, -1.0288, -1.2607,\n",
       "         -1.0117, -0.9244, -0.9333, -1.1437, -0.9427, -1.0012, -1.3149, -0.9536,\n",
       "         -2.4461, -1.0281, -2.9739, -1.0230, -3.3517, -0.9279, -0.9878, -0.9194,\n",
       "         -0.9464, -0.9259, -0.9465, -6.2025, -0.9506, -0.9827, -1.2984, -0.9783,\n",
       "         -4.0000, -0.9520, -1.0207, -1.7030, -0.9424, -1.0095, -2.2161, -0.9402,\n",
       "         -1.2631, -1.9841, -0.9859, -1.9162, -1.0390, -1.1155, -1.4812, -0.9576,\n",
       "         -1.2061, -1.3094, -1.2706, -1.4157, -5.0095, -0.9436, -1.3303, -1.4952,\n",
       "         -0.9210, -1.0307, -0.9780, -1.5229, -1.2042, -0.9519, -1.1153, -0.9687,\n",
       "         -0.9315, -3.0009, -1.0705, -1.0490, -1.4568, -1.3879, -1.4139, -0.9725,\n",
       "         -2.3310, -0.9266, -0.9213, -0.9268, -1.7955, -0.9252, -3.5011, -1.3103,\n",
       "         -0.9333, -0.9211, -0.9253, -0.9229, -0.9199, -0.9960, -0.9450, -1.6616,\n",
       "         -1.6837, -1.5221, -1.3779, -0.9694, -1.4109, -1.0229, -1.1571, -0.9765,\n",
       "         -0.9242, -0.9761, -1.5833, -0.9190, -1.7446, -0.9779, -1.4737, -1.8378,\n",
       "         -0.9724, -1.5264, -0.9195, -0.9300, -1.0025, -1.1315, -1.8913, -1.0412,\n",
       "         -0.9212, -0.9475, -3.5798, -1.0610, -4.3244, -1.5040, -0.9455, -0.9560,\n",
       "         -0.9280, -1.5165, -1.1705, -0.9246, -1.2280, -0.9776, -1.3408, -0.9548,\n",
       "         -1.0541, -1.0445, -0.9209, -0.9290, -1.5482, -0.9843, -1.0226, -1.1747,\n",
       "         -0.9237, -1.4789, -1.4330, -1.9491, -1.8545, -1.3879, -1.2899, -0.9357,\n",
       "         -1.4898, -3.9778, -1.7081, -1.1020, -1.3769, -1.0799, -0.9947, -2.4213,\n",
       "         -1.1434, -1.1262, -0.9339, -3.1470, -1.4575, -3.6437, -1.0534, -0.9257,\n",
       "         -1.7454, -2.0046, -1.0449, -1.4901, -0.9597, -1.2139, -1.1962, -1.2314,\n",
       "         -1.5513, -1.1112, -1.4660, -1.0096, -1.6214, -1.5991, -2.0001, -3.1481,\n",
       "         -0.9611, -1.1587, -0.9819, -0.9450, -1.0093, -1.1589, -1.1750, -2.8555,\n",
       "         -0.9263, -1.9766, -2.5230, -1.1812, -1.0859, -0.9198, -4.4586, -0.9536,\n",
       "         -2.9581, -1.7393, -0.9562, -1.3661, -1.1900, -0.9854, -0.9704, -2.4017,\n",
       "         -1.2281, -3.0904, -1.0652, -1.2187, -0.9303, -1.2524, -1.0653, -1.0830,\n",
       "         -1.7906, -1.0228, -0.9739, -1.3817, -1.5081, -4.0472, -0.9216, -0.9619,\n",
       "         -1.5599, -0.9428, -1.0541, -0.9246, -1.4083, -0.9212, -0.9220, -3.4543,\n",
       "         -1.0631, -1.1556, -2.4079, -1.6971, -0.9799, -1.8999, -1.3474, -0.9405,\n",
       "         -1.5052, -1.1986, -1.0677, -0.9847, -1.0640, -1.0974, -1.3036, -0.9195,\n",
       "         -0.9738, -3.6078, -1.2117, -1.0344, -1.4096, -0.9436, -0.9307, -0.9402,\n",
       "         -0.9474, -2.1385, -0.9533, -1.0655, -3.4944, -1.2996, -0.9284, -1.7770,\n",
       "         -1.0102, -1.2553, -0.9747, -1.4056, -1.1661, -1.4686, -1.6476, -1.7289,\n",
       "         -1.1258, -0.9237, -2.4581, -1.7582, -2.3363, -0.9668, -1.9956, -2.0994,\n",
       "         -1.2552, -1.5182, -1.4433, -1.1528, -1.8709, -0.9191, -1.0979, -1.9231,\n",
       "         -0.9268, -4.0637, -1.2931, -1.1167, -1.1897, -1.3408, -1.2597, -0.9265,\n",
       "         -0.9209, -1.6626, -1.3293, -0.9205, -1.4360, -1.2479, -3.0413, -1.5691,\n",
       "         -0.9224, -1.6705, -0.9190, -1.4181, -2.6760, -1.2135, -0.9635, -0.9190,\n",
       "         -1.0218, -2.2966, -4.0112, -1.0929, -1.5167, -1.2508, -1.1014, -2.8293,\n",
       "         -1.8487, -1.0295, -0.9588, -2.3983, -1.3436, -1.6896, -2.5659, -0.9189,\n",
       "         -0.9405, -0.9762, -1.1447, -1.0643, -1.3012, -1.2813, -1.0758, -0.9435,\n",
       "         -0.9444, -1.3695, -1.0915, -1.0089, -1.2650, -0.9198, -1.3254, -1.0893,\n",
       "         -0.9908, -1.1699, -1.0794, -0.9212, -1.6346, -1.0892, -0.9894, -1.0184,\n",
       "         -0.9189, -0.9281, -1.1440, -4.0420, -0.9281, -0.9868, -0.9566, -0.9438,\n",
       "         -1.1249, -1.4626, -1.1969, -0.9311, -0.9294, -1.0763, -1.3628, -1.9476,\n",
       "         -0.9214, -1.5481, -3.6936, -1.1850, -1.0869, -0.9199, -1.2321, -0.9482,\n",
       "         -0.9251, -1.7440, -1.2306, -1.7009, -2.5530, -1.6508, -0.9628, -1.0108,\n",
       "         -2.0305, -1.1646, -1.1518, -0.9966, -1.4576, -1.7664, -0.9244, -1.6891,\n",
       "         -0.9319, -0.9481, -2.7361, -1.4425, -1.0524, -1.1929, -1.0770, -1.3560,\n",
       "         -1.1937, -0.9293, -2.7707, -0.9467, -0.9526, -1.5633, -0.9191, -2.0045,\n",
       "         -1.0899, -1.6807, -3.5385, -4.2741, -0.9412, -1.2461, -1.5850, -0.9247,\n",
       "         -0.9769, -3.0863, -1.4103, -1.0812, -1.5515, -1.0141, -1.0016, -0.9466,\n",
       "         -1.8413, -1.0443, -1.0707, -1.4798, -1.6915, -1.0912, -0.9333, -0.9620,\n",
       "         -1.3777, -1.0014, -0.9332, -1.0315, -1.3011, -1.0927, -0.9240, -1.2105,\n",
       "         -1.4491, -1.6421, -0.9198, -1.2962, -0.9190, -0.9300, -2.3110, -0.9425,\n",
       "         -0.9243, -2.2966, -1.0967, -0.9619, -1.9958, -1.0021, -1.1740, -1.0226,\n",
       "         -1.7842, -0.9692, -1.3436, -0.9571, -0.9191, -1.5468, -0.9729, -0.9209,\n",
       "         -1.4098, -1.1387, -2.0182, -0.9201, -1.1483, -0.9359, -3.2572, -1.0681,\n",
       "         -0.9234, -2.9690, -0.9281, -1.2228, -0.9199, -1.0850, -1.6825, -1.0815,\n",
       "         -1.6039, -0.9235, -0.9433, -0.9191, -0.9511, -1.0722, -1.0130, -1.0097,\n",
       "         -0.9215, -1.0465, -0.9896, -1.1884, -1.4510, -0.9300, -2.6182, -1.1252]),\n",
       " [[tensor(-2.9558),\n",
       "   tensor(-3.0310),\n",
       "   tensor(-3.3489),\n",
       "   tensor(-3.9019),\n",
       "   tensor(-4.8585),\n",
       "   tensor(-6.0818),\n",
       "   tensor(-7.5080),\n",
       "   tensor(-8.7679),\n",
       "   tensor(-10.5679),\n",
       "   tensor(-12.5256),\n",
       "   tensor(-11.0256),\n",
       "   tensor(-9.4689),\n",
       "   tensor(-7.9435),\n",
       "   tensor(-6.5067),\n",
       "   tensor(-5.3283),\n",
       "   tensor(-4.3993),\n",
       "   tensor(-3.7381),\n",
       "   tensor(-3.3690),\n",
       "   tensor(-3.2667),\n",
       "   tensor(-3.4040),\n",
       "   tensor(-3.6628),\n",
       "   tensor(-4.2273),\n",
       "   tensor(-4.8424),\n",
       "   tensor(-6.0090),\n",
       "   tensor(-7.3423),\n",
       "   tensor(-8.8544),\n",
       "   tensor(-10.5157),\n",
       "   tensor(-12.0949),\n",
       "   tensor(-10.8712),\n",
       "   tensor(-9.4637),\n",
       "   tensor(-7.9414),\n",
       "   tensor(-6.6127),\n",
       "   tensor(-5.5985),\n",
       "   tensor(-4.5918),\n",
       "   tensor(-3.8935),\n",
       "   tensor(-3.3410),\n",
       "   tensor(-3.0946),\n",
       "   tensor(-3.2279),\n",
       "   tensor(-3.6027),\n",
       "   tensor(-4.2344),\n",
       "   tensor(-5.0390),\n",
       "   tensor(-6.1733),\n",
       "   tensor(-7.2109),\n",
       "   tensor(-8.6503),\n",
       "   tensor(-10.3686),\n",
       "   tensor(-12.1962),\n",
       "   tensor(-11.0301),\n",
       "   tensor(-9.3878),\n",
       "   tensor(-8.0177),\n",
       "   tensor(-6.8243),\n",
       "   tensor(-5.6043),\n",
       "   tensor(-4.5981),\n",
       "   tensor(-3.7338),\n",
       "   tensor(-3.1914),\n",
       "   tensor(-2.8557),\n",
       "   tensor(-2.7342),\n",
       "   tensor(-2.8501),\n",
       "   tensor(-3.1730),\n",
       "   tensor(-3.7105),\n",
       "   tensor(-4.5358),\n",
       "   tensor(-5.7625),\n",
       "   tensor(-7.1561),\n",
       "   tensor(-8.8010),\n",
       "   tensor(-10.5080),\n",
       "   tensor(-12.6051),\n",
       "   tensor(-11.5256),\n",
       "   tensor(-9.6968),\n",
       "   tensor(-7.9659),\n",
       "   tensor(-6.5773),\n",
       "   tensor(-5.3162),\n",
       "   tensor(-4.3753),\n",
       "   tensor(-3.6690),\n",
       "   tensor(-3.1848),\n",
       "   tensor(-3.0574),\n",
       "   tensor(-3.0960),\n",
       "   tensor(-3.3537),\n",
       "   tensor(-3.7947),\n",
       "   tensor(-4.3177),\n",
       "   tensor(-5.1318),\n",
       "   tensor(-6.4239),\n",
       "   tensor(-7.8172),\n",
       "   tensor(-9.3990),\n",
       "   tensor(-11.3201),\n",
       "   tensor(-12.1714),\n",
       "   tensor(-10.7518),\n",
       "   tensor(-9.1075),\n",
       "   tensor(-7.4782),\n",
       "   tensor(-5.8640),\n",
       "   tensor(-4.6040),\n",
       "   tensor(-3.8879),\n",
       "   tensor(-3.1831),\n",
       "   tensor(-2.8698),\n",
       "   tensor(-2.7069),\n",
       "   tensor(-2.8048),\n",
       "   tensor(-3.2100),\n",
       "   tensor(-3.7607),\n",
       "   tensor(-4.7834),\n",
       "   tensor(-5.9156),\n",
       "   tensor(-7.3189),\n",
       "   tensor(-9.1944),\n",
       "   tensor(-11.0034),\n",
       "   tensor(-12.4983),\n",
       "   tensor(-11.2504),\n",
       "   tensor(-9.4566),\n",
       "   tensor(-7.9114),\n",
       "   tensor(-6.4134),\n",
       "   tensor(-5.2579),\n",
       "   tensor(-4.2718),\n",
       "   tensor(-3.6144),\n",
       "   tensor(-3.1373),\n",
       "   tensor(-2.9189),\n",
       "   tensor(-2.9334),\n",
       "   tensor(-3.1623),\n",
       "   tensor(-3.6733),\n",
       "   tensor(-4.4945),\n",
       "   tensor(-5.6506),\n",
       "   tensor(-7.1309),\n",
       "   tensor(-9.0386),\n",
       "   tensor(-10.5865),\n",
       "   tensor(-12.3750),\n",
       "   tensor(-11.1534),\n",
       "   tensor(-9.7419),\n",
       "   tensor(-8.0141),\n",
       "   tensor(-6.6539),\n",
       "   tensor(-5.5293),\n",
       "   tensor(-4.5597),\n",
       "   tensor(-3.9059),\n",
       "   tensor(-3.4127),\n",
       "   tensor(-3.1139),\n",
       "   tensor(-3.0081),\n",
       "   tensor(-3.1707),\n",
       "   tensor(-3.6083),\n",
       "   tensor(-4.3740),\n",
       "   tensor(-5.3396),\n",
       "   tensor(-6.3790),\n",
       "   tensor(-7.7744),\n",
       "   tensor(-9.4275),\n",
       "   tensor(-11.1072),\n",
       "   tensor(-12.0161),\n",
       "   tensor(-10.3259),\n",
       "   tensor(-8.9528),\n",
       "   tensor(-7.5250),\n",
       "   tensor(-6.1530),\n",
       "   tensor(-5.2072),\n",
       "   tensor(-4.3319),\n",
       "   tensor(-3.7898),\n",
       "   tensor(-3.5380),\n",
       "   tensor(-3.5721),\n",
       "   tensor(-3.9764),\n",
       "   tensor(-4.6192),\n",
       "   tensor(-5.3760),\n",
       "   tensor(-6.4241),\n",
       "   tensor(-7.6957),\n",
       "   tensor(-9.1278),\n",
       "   tensor(-10.7313),\n",
       "   tensor(-11.7300),\n",
       "   tensor(-10.2748),\n",
       "   tensor(-8.8817),\n",
       "   tensor(-7.6007),\n",
       "   tensor(-6.6225),\n",
       "   tensor(-5.5135),\n",
       "   tensor(-4.7738),\n",
       "   tensor(-4.1565),\n",
       "   tensor(-3.7126),\n",
       "   tensor(-3.5535),\n",
       "   tensor(-3.7635),\n",
       "   tensor(-4.2039),\n",
       "   tensor(-4.8229),\n",
       "   tensor(-5.4915),\n",
       "   tensor(-6.7520),\n",
       "   tensor(-8.1002),\n",
       "   tensor(-9.7531),\n",
       "   tensor(-11.5982),\n",
       "   tensor(-11.3716),\n",
       "   tensor(-10.1110),\n",
       "   tensor(-8.5889),\n",
       "   tensor(-7.2887),\n",
       "   tensor(-6.1225),\n",
       "   tensor(-4.7379),\n",
       "   tensor(-3.8282),\n",
       "   tensor(-3.1537),\n",
       "   tensor(-2.7904),\n",
       "   tensor(-2.6283),\n",
       "   tensor(-2.6612),\n",
       "   tensor(-2.8740),\n",
       "   tensor(-3.3333),\n",
       "   tensor(-4.0626),\n",
       "   tensor(-4.9942),\n",
       "   tensor(-6.3465),\n",
       "   tensor(-7.8940),\n",
       "   tensor(-9.5890),\n",
       "   tensor(-11.4086),\n",
       "   tensor(-12.4409),\n",
       "   tensor(-10.9138),\n",
       "   tensor(-9.2177),\n",
       "   tensor(-7.4647),\n",
       "   tensor(-5.9936),\n",
       "   tensor(-4.8477),\n",
       "   tensor(-3.8841),\n",
       "   tensor(-3.1349)],\n",
       "  [tensor(-0.2002),\n",
       "   tensor(-0.1567),\n",
       "   tensor(-0.1391),\n",
       "   tensor(-0.1442),\n",
       "   tensor(-0.1695),\n",
       "   tensor(-0.2400),\n",
       "   tensor(-0.3851),\n",
       "   tensor(-0.5172),\n",
       "   tensor(-0.8246),\n",
       "   tensor(-1.1331),\n",
       "   tensor(-1.5786),\n",
       "   tensor(-2.2845),\n",
       "   tensor(-3.3948),\n",
       "   tensor(-4.7485),\n",
       "   tensor(-6.5145),\n",
       "   tensor(-8.2591),\n",
       "   tensor(-10.3707),\n",
       "   tensor(-12.7164),\n",
       "   tensor(-14.8663),\n",
       "   tensor(-12.7672),\n",
       "   tensor(-10.3521),\n",
       "   tensor(-8.4713),\n",
       "   tensor(-6.6932),\n",
       "   tensor(-4.9532),\n",
       "   tensor(-3.4444),\n",
       "   tensor(-2.5636),\n",
       "   tensor(-1.8469),\n",
       "   tensor(-1.3708),\n",
       "   tensor(-1.0382),\n",
       "   tensor(-0.8772),\n",
       "   tensor(-0.8856),\n",
       "   tensor(-1.0172),\n",
       "   tensor(-1.2828),\n",
       "   tensor(-1.7066),\n",
       "   tensor(-2.3414),\n",
       "   tensor(-3.1491),\n",
       "   tensor(-4.3040),\n",
       "   tensor(-5.8803),\n",
       "   tensor(-7.7821),\n",
       "   tensor(-9.8585),\n",
       "   tensor(-11.9982),\n",
       "   tensor(-14.1020),\n",
       "   tensor(-12.2968),\n",
       "   tensor(-10.3543),\n",
       "   tensor(-8.3710),\n",
       "   tensor(-6.5050),\n",
       "   tensor(-4.9589),\n",
       "   tensor(-3.7979),\n",
       "   tensor(-2.9023),\n",
       "   tensor(-2.2718),\n",
       "   tensor(-1.7350),\n",
       "   tensor(-1.4578),\n",
       "   tensor(-1.3436),\n",
       "   tensor(-1.4258),\n",
       "   tensor(-1.6043),\n",
       "   tensor(-1.9620),\n",
       "   tensor(-2.5448),\n",
       "   tensor(-3.6235),\n",
       "   tensor(-4.8941),\n",
       "   tensor(-6.4797),\n",
       "   tensor(-8.1017),\n",
       "   tensor(-10.1444),\n",
       "   tensor(-12.7002),\n",
       "   tensor(-13.5117),\n",
       "   tensor(-11.5892),\n",
       "   tensor(-9.5187),\n",
       "   tensor(-7.8232),\n",
       "   tensor(-6.0693),\n",
       "   tensor(-4.6961),\n",
       "   tensor(-3.3966),\n",
       "   tensor(-2.5883),\n",
       "   tensor(-1.9918),\n",
       "   tensor(-1.5449),\n",
       "   tensor(-1.2727),\n",
       "   tensor(-1.1795),\n",
       "   tensor(-1.2747),\n",
       "   tensor(-1.5433),\n",
       "   tensor(-1.8949),\n",
       "   tensor(-2.4621),\n",
       "   tensor(-3.5497),\n",
       "   tensor(-4.9010),\n",
       "   tensor(-6.7001),\n",
       "   tensor(-8.8993),\n",
       "   tensor(-11.1658),\n",
       "   tensor(-13.5516),\n",
       "   tensor(-13.8995),\n",
       "   tensor(-11.9569),\n",
       "   tensor(-9.8819),\n",
       "   tensor(-7.6470),\n",
       "   tensor(-5.9343),\n",
       "   tensor(-4.3796),\n",
       "   tensor(-3.2477),\n",
       "   tensor(-2.1157),\n",
       "   tensor(-1.4641),\n",
       "   tensor(-1.0229),\n",
       "   tensor(-0.7007),\n",
       "   tensor(-0.4613),\n",
       "   tensor(-0.3541),\n",
       "   tensor(-0.3299),\n",
       "   tensor(-0.3884),\n",
       "   tensor(-0.5186),\n",
       "   tensor(-0.6228),\n",
       "   tensor(-0.8837),\n",
       "   tensor(-1.2059),\n",
       "   tensor(-1.6016),\n",
       "   tensor(-2.3248),\n",
       "   tensor(-3.3664),\n",
       "   tensor(-4.8310),\n",
       "   tensor(-6.8306),\n",
       "   tensor(-8.8991),\n",
       "   tensor(-11.4293),\n",
       "   tensor(-14.1272),\n",
       "   tensor(-14.5223),\n",
       "   tensor(-12.4628),\n",
       "   tensor(-9.8354),\n",
       "   tensor(-7.4390),\n",
       "   tensor(-5.7450),\n",
       "   tensor(-4.3542),\n",
       "   tensor(-3.1087),\n",
       "   tensor(-2.3919),\n",
       "   tensor(-1.7006),\n",
       "   tensor(-1.2231),\n",
       "   tensor(-0.8068),\n",
       "   tensor(-0.5996),\n",
       "   tensor(-0.5058),\n",
       "   tensor(-0.5015),\n",
       "   tensor(-0.6078),\n",
       "   tensor(-0.8817),\n",
       "   tensor(-1.2760),\n",
       "   tensor(-1.7672),\n",
       "   tensor(-2.5948),\n",
       "   tensor(-3.5969),\n",
       "   tensor(-4.7822),\n",
       "   tensor(-6.6228),\n",
       "   tensor(-8.5587),\n",
       "   tensor(-11.1345),\n",
       "   tensor(-13.3876),\n",
       "   tensor(-14.3321),\n",
       "   tensor(-12.2210),\n",
       "   tensor(-10.0951),\n",
       "   tensor(-8.0722),\n",
       "   tensor(-5.8968),\n",
       "   tensor(-4.5818),\n",
       "   tensor(-3.2899),\n",
       "   tensor(-2.3120),\n",
       "   tensor(-1.5725),\n",
       "   tensor(-1.1784),\n",
       "   tensor(-0.8689),\n",
       "   tensor(-0.6886),\n",
       "   tensor(-0.5408),\n",
       "   tensor(-0.4721),\n",
       "   tensor(-0.4824),\n",
       "   tensor(-0.5455),\n",
       "   tensor(-0.7558),\n",
       "   tensor(-0.9912),\n",
       "   tensor(-1.4521),\n",
       "   tensor(-2.0280),\n",
       "   tensor(-2.9108),\n",
       "   tensor(-4.1220),\n",
       "   tensor(-5.4301),\n",
       "   tensor(-7.5746),\n",
       "   tensor(-9.9180),\n",
       "   tensor(-12.4583),\n",
       "   tensor(-14.8104),\n",
       "   tensor(-13.0870),\n",
       "   tensor(-11.1528),\n",
       "   tensor(-9.1602),\n",
       "   tensor(-7.0819),\n",
       "   tensor(-5.3532),\n",
       "   tensor(-4.0360),\n",
       "   tensor(-2.9760),\n",
       "   tensor(-2.0159),\n",
       "   tensor(-1.3768),\n",
       "   tensor(-0.9451),\n",
       "   tensor(-0.7144),\n",
       "   tensor(-0.5263),\n",
       "   tensor(-0.4250),\n",
       "   tensor(-0.3467),\n",
       "   tensor(-0.3248),\n",
       "   tensor(-0.3837),\n",
       "   tensor(-0.4826),\n",
       "   tensor(-0.5786),\n",
       "   tensor(-0.8980),\n",
       "   tensor(-1.4281),\n",
       "   tensor(-2.1011),\n",
       "   tensor(-3.1363),\n",
       "   tensor(-4.2647),\n",
       "   tensor(-6.1155),\n",
       "   tensor(-8.2620),\n",
       "   tensor(-10.4845),\n",
       "   tensor(-13.1083),\n",
       "   tensor(-15.6491),\n",
       "   tensor(-13.1383),\n",
       "   tensor(-10.8119),\n",
       "   tensor(-8.7363),\n",
       "   tensor(-6.8804),\n",
       "   tensor(-5.1040),\n",
       "   tensor(-3.7519),\n",
       "   tensor(-2.7390),\n",
       "   tensor(-1.9402)],\n",
       "  [tensor(-1.5993),\n",
       "   tensor(-1.6017),\n",
       "   tensor(-1.7878),\n",
       "   tensor(-2.1356),\n",
       "   tensor(-2.6351),\n",
       "   tensor(-3.4439),\n",
       "   tensor(-4.5333),\n",
       "   tensor(-5.6158),\n",
       "   tensor(-7.3863),\n",
       "   tensor(-9.2026),\n",
       "   tensor(-11.1630),\n",
       "   tensor(-13.2713),\n",
       "   tensor(-11.9277),\n",
       "   tensor(-10.0163),\n",
       "   tensor(-8.4094),\n",
       "   tensor(-6.7431),\n",
       "   tensor(-5.1781),\n",
       "   tensor(-3.9639),\n",
       "   tensor(-3.0217),\n",
       "   tensor(-2.4887),\n",
       "   tensor(-2.1817),\n",
       "   tensor(-2.0395),\n",
       "   tensor(-2.1056),\n",
       "   tensor(-2.3253),\n",
       "   tensor(-2.8467),\n",
       "   tensor(-3.5129),\n",
       "   tensor(-4.2584),\n",
       "   tensor(-5.5717),\n",
       "   tensor(-7.1059),\n",
       "   tensor(-9.0174),\n",
       "   tensor(-11.1892),\n",
       "   tensor(-13.7086),\n",
       "   tensor(-12.1686),\n",
       "   tensor(-10.1213),\n",
       "   tensor(-8.1596),\n",
       "   tensor(-6.4407),\n",
       "   tensor(-5.0679),\n",
       "   tensor(-3.8943),\n",
       "   tensor(-2.9370),\n",
       "   tensor(-2.2865),\n",
       "   tensor(-1.9578),\n",
       "   tensor(-1.8635),\n",
       "   tensor(-2.0491),\n",
       "   tensor(-2.4653),\n",
       "   tensor(-3.1384),\n",
       "   tensor(-4.0411),\n",
       "   tensor(-5.0955),\n",
       "   tensor(-6.5688),\n",
       "   tensor(-8.1119),\n",
       "   tensor(-10.3859),\n",
       "   tensor(-12.2702),\n",
       "   tensor(-12.6551),\n",
       "   tensor(-10.7638),\n",
       "   tensor(-9.0548),\n",
       "   tensor(-7.1632),\n",
       "   tensor(-5.8081),\n",
       "   tensor(-4.4948),\n",
       "   tensor(-3.5171),\n",
       "   tensor(-2.8388),\n",
       "   tensor(-2.4029),\n",
       "   tensor(-2.2332),\n",
       "   tensor(-2.2773),\n",
       "   tensor(-2.4950),\n",
       "   tensor(-2.9516),\n",
       "   tensor(-3.7639),\n",
       "   tensor(-5.0579),\n",
       "   tensor(-6.8113),\n",
       "   tensor(-8.7206),\n",
       "   tensor(-10.6847),\n",
       "   tensor(-12.9804),\n",
       "   tensor(-12.6514),\n",
       "   tensor(-10.7105),\n",
       "   tensor(-8.6611),\n",
       "   tensor(-6.9383),\n",
       "   tensor(-5.4106),\n",
       "   tensor(-4.1052),\n",
       "   tensor(-3.1861),\n",
       "   tensor(-2.5848),\n",
       "   tensor(-2.1554),\n",
       "   tensor(-1.8921),\n",
       "   tensor(-1.7826),\n",
       "   tensor(-1.8783),\n",
       "   tensor(-2.2803),\n",
       "   tensor(-3.0050),\n",
       "   tensor(-3.9805),\n",
       "   tensor(-5.2180),\n",
       "   tensor(-6.7660),\n",
       "   tensor(-8.8985),\n",
       "   tensor(-11.2161),\n",
       "   tensor(-13.2460),\n",
       "   tensor(-12.6562),\n",
       "   tensor(-10.5901),\n",
       "   tensor(-8.7340),\n",
       "   tensor(-7.1093),\n",
       "   tensor(-5.5723),\n",
       "   tensor(-4.0839),\n",
       "   tensor(-3.0673),\n",
       "   tensor(-2.3307),\n",
       "   tensor(-1.8620),\n",
       "   tensor(-1.6535),\n",
       "   tensor(-1.6330),\n",
       "   tensor(-1.8394),\n",
       "   tensor(-2.2474),\n",
       "   tensor(-3.0725),\n",
       "   tensor(-3.8535),\n",
       "   tensor(-4.9078),\n",
       "   tensor(-6.4245),\n",
       "   tensor(-8.2317),\n",
       "   tensor(-10.6382),\n",
       "   tensor(-13.1898),\n",
       "   tensor(-13.3650),\n",
       "   tensor(-11.2112),\n",
       "   tensor(-9.0731),\n",
       "   tensor(-7.2053),\n",
       "   tensor(-5.6546),\n",
       "   tensor(-4.2671),\n",
       "   tensor(-3.1859),\n",
       "   tensor(-2.3442),\n",
       "   tensor(-1.7990),\n",
       "   tensor(-1.4686),\n",
       "   tensor(-1.3856),\n",
       "   tensor(-1.5464),\n",
       "   tensor(-1.8720),\n",
       "   tensor(-2.4575),\n",
       "   tensor(-3.2737),\n",
       "   tensor(-4.3856),\n",
       "   tensor(-5.9945),\n",
       "   tensor(-8.0277),\n",
       "   tensor(-10.1930),\n",
       "   tensor(-12.2595),\n",
       "   tensor(-13.9513),\n",
       "   tensor(-12.0127),\n",
       "   tensor(-9.9248),\n",
       "   tensor(-8.0800),\n",
       "   tensor(-6.2625),\n",
       "   tensor(-4.7724),\n",
       "   tensor(-3.5214),\n",
       "   tensor(-2.5177),\n",
       "   tensor(-1.9440),\n",
       "   tensor(-1.5427),\n",
       "   tensor(-1.4045),\n",
       "   tensor(-1.4145),\n",
       "   tensor(-1.6143),\n",
       "   tensor(-1.9415),\n",
       "   tensor(-2.4561),\n",
       "   tensor(-3.3478),\n",
       "   tensor(-4.5385),\n",
       "   tensor(-5.6777),\n",
       "   tensor(-7.4084),\n",
       "   tensor(-9.6525),\n",
       "   tensor(-12.1359),\n",
       "   tensor(-13.9148),\n",
       "   tensor(-12.1447),\n",
       "   tensor(-10.1524),\n",
       "   tensor(-8.1289),\n",
       "   tensor(-6.3894),\n",
       "   tensor(-4.8343),\n",
       "   tensor(-3.6727),\n",
       "   tensor(-2.8030),\n",
       "   tensor(-2.2308),\n",
       "   tensor(-1.7919),\n",
       "   tensor(-1.5467),\n",
       "   tensor(-1.5744),\n",
       "   tensor(-1.7546),\n",
       "   tensor(-2.1651),\n",
       "   tensor(-2.9766),\n",
       "   tensor(-3.9800),\n",
       "   tensor(-4.9831),\n",
       "   tensor(-6.5685),\n",
       "   tensor(-8.5989),\n",
       "   tensor(-10.9392),\n",
       "   tensor(-13.2279),\n",
       "   tensor(-13.1011),\n",
       "   tensor(-10.9195),\n",
       "   tensor(-9.2130),\n",
       "   tensor(-7.2211),\n",
       "   tensor(-5.5449),\n",
       "   tensor(-4.0228),\n",
       "   tensor(-3.0407),\n",
       "   tensor(-2.3379),\n",
       "   tensor(-1.8664),\n",
       "   tensor(-1.6192),\n",
       "   tensor(-1.6010),\n",
       "   tensor(-1.7562),\n",
       "   tensor(-2.0783),\n",
       "   tensor(-2.6752),\n",
       "   tensor(-3.4327),\n",
       "   tensor(-4.4700),\n",
       "   tensor(-5.8106),\n",
       "   tensor(-7.4969),\n",
       "   tensor(-9.2755),\n",
       "   tensor(-11.1659),\n",
       "   tensor(-13.2620),\n",
       "   tensor(-11.8613),\n",
       "   tensor(-9.9773),\n",
       "   tensor(-8.3338),\n",
       "   tensor(-6.5998),\n",
       "   tensor(-5.2095),\n",
       "   tensor(-4.0621),\n",
       "   tensor(-3.2112)],\n",
       "  [tensor(-4.3961),\n",
       "   tensor(-4.8433),\n",
       "   tensor(-5.4791),\n",
       "   tensor(-6.5227),\n",
       "   tensor(-7.6846),\n",
       "   tensor(-9.0112),\n",
       "   tensor(-10.4187),\n",
       "   tensor(-11.4999),\n",
       "   tensor(-10.3648),\n",
       "   tensor(-9.0459),\n",
       "   tensor(-7.8758),\n",
       "   tensor(-6.5611),\n",
       "   tensor(-5.5925),\n",
       "   tensor(-4.5175),\n",
       "   tensor(-3.8754),\n",
       "   tensor(-3.4618),\n",
       "   tensor(-3.2716),\n",
       "   tensor(-3.3078),\n",
       "   tensor(-3.7058),\n",
       "   tensor(-4.4141),\n",
       "   tensor(-5.2769),\n",
       "   tensor(-6.3905),\n",
       "   tensor(-7.6102),\n",
       "   tensor(-9.1274),\n",
       "   tensor(-10.6752),\n",
       "   tensor(-11.9501),\n",
       "   tensor(-10.5770),\n",
       "   tensor(-9.1921),\n",
       "   tensor(-7.7984),\n",
       "   tensor(-6.4429),\n",
       "   tensor(-5.4362),\n",
       "   tensor(-4.5289),\n",
       "   tensor(-3.7920),\n",
       "   tensor(-3.3411),\n",
       "   tensor(-3.0057),\n",
       "   tensor(-2.9090),\n",
       "   tensor(-3.0582),\n",
       "   tensor(-3.5317),\n",
       "   tensor(-4.3311),\n",
       "   tensor(-5.4812),\n",
       "   tensor(-6.9113),\n",
       "   tensor(-8.3615),\n",
       "   tensor(-9.8849),\n",
       "   tensor(-11.4164),\n",
       "   tensor(-11.6920),\n",
       "   tensor(-10.2248),\n",
       "   tensor(-8.6635),\n",
       "   tensor(-7.3178),\n",
       "   tensor(-6.0081),\n",
       "   tensor(-4.9395),\n",
       "   tensor(-4.1170),\n",
       "   tensor(-3.3556),\n",
       "   tensor(-2.9071),\n",
       "   tensor(-2.8279),\n",
       "   tensor(-2.9518),\n",
       "   tensor(-3.3521),\n",
       "   tensor(-3.8670),\n",
       "   tensor(-4.6510),\n",
       "   tensor(-5.8712),\n",
       "   tensor(-7.1816),\n",
       "   tensor(-8.6902),\n",
       "   tensor(-10.4291),\n",
       "   tensor(-11.9353),\n",
       "   tensor(-11.1602),\n",
       "   tensor(-9.6451),\n",
       "   tensor(-8.3155),\n",
       "   tensor(-6.8513),\n",
       "   tensor(-5.7263),\n",
       "   tensor(-4.7497),\n",
       "   tensor(-3.8414),\n",
       "   tensor(-3.3368),\n",
       "   tensor(-3.1015),\n",
       "   tensor(-3.1634),\n",
       "   tensor(-3.5454),\n",
       "   tensor(-4.2740),\n",
       "   tensor(-5.3208),\n",
       "   tensor(-6.3377),\n",
       "   tensor(-7.6345),\n",
       "   tensor(-9.2247),\n",
       "   tensor(-10.8994),\n",
       "   tensor(-12.1254),\n",
       "   tensor(-10.6471),\n",
       "   tensor(-9.1337),\n",
       "   tensor(-7.6367),\n",
       "   tensor(-6.2781),\n",
       "   tensor(-5.3235),\n",
       "   tensor(-4.3965),\n",
       "   tensor(-3.6806),\n",
       "   tensor(-3.0965),\n",
       "   tensor(-2.8439),\n",
       "   tensor(-2.9480),\n",
       "   tensor(-3.3955),\n",
       "   tensor(-4.1422),\n",
       "   tensor(-5.2660),\n",
       "   tensor(-6.6042),\n",
       "   tensor(-8.2681),\n",
       "   tensor(-10.1195),\n",
       "   tensor(-11.8532),\n",
       "   tensor(-11.8337),\n",
       "   tensor(-10.4057),\n",
       "   tensor(-8.7643),\n",
       "   tensor(-7.3188),\n",
       "   tensor(-5.7542),\n",
       "   tensor(-4.7238),\n",
       "   tensor(-3.8145),\n",
       "   tensor(-3.2295),\n",
       "   tensor(-2.8572),\n",
       "   tensor(-2.6550),\n",
       "   tensor(-2.6596),\n",
       "   tensor(-2.8931),\n",
       "   tensor(-3.4164),\n",
       "   tensor(-4.3005),\n",
       "   tensor(-5.5007),\n",
       "   tensor(-6.9653),\n",
       "   tensor(-8.8395),\n",
       "   tensor(-10.8733),\n",
       "   tensor(-12.7070),\n",
       "   tensor(-11.5588),\n",
       "   tensor(-9.9957),\n",
       "   tensor(-8.2780),\n",
       "   tensor(-6.7340),\n",
       "   tensor(-5.3735),\n",
       "   tensor(-4.2500),\n",
       "   tensor(-3.5789),\n",
       "   tensor(-2.9594),\n",
       "   tensor(-2.6280),\n",
       "   tensor(-2.5170),\n",
       "   tensor(-2.6044),\n",
       "   tensor(-2.8947),\n",
       "   tensor(-3.4594),\n",
       "   tensor(-4.3083),\n",
       "   tensor(-5.6831),\n",
       "   tensor(-7.0545),\n",
       "   tensor(-8.3673),\n",
       "   tensor(-9.8872),\n",
       "   tensor(-11.8156),\n",
       "   tensor(-11.6646),\n",
       "   tensor(-10.0757),\n",
       "   tensor(-8.5698),\n",
       "   tensor(-7.0505),\n",
       "   tensor(-5.9162),\n",
       "   tensor(-4.9146),\n",
       "   tensor(-4.1290),\n",
       "   tensor(-3.5347),\n",
       "   tensor(-3.2688),\n",
       "   tensor(-3.3279),\n",
       "   tensor(-3.6484),\n",
       "   tensor(-4.1493),\n",
       "   tensor(-4.8909),\n",
       "   tensor(-5.9916),\n",
       "   tensor(-7.0634),\n",
       "   tensor(-8.1666),\n",
       "   tensor(-9.7108),\n",
       "   tensor(-11.5982),\n",
       "   tensor(-11.3755),\n",
       "   tensor(-9.7209),\n",
       "   tensor(-8.2154),\n",
       "   tensor(-6.9459),\n",
       "   tensor(-5.9607),\n",
       "   tensor(-4.9824),\n",
       "   tensor(-4.1865),\n",
       "   tensor(-3.6287),\n",
       "   tensor(-3.3976),\n",
       "   tensor(-3.3733),\n",
       "   tensor(-3.6746),\n",
       "   tensor(-4.2691),\n",
       "   tensor(-5.2274),\n",
       "   tensor(-6.2197),\n",
       "   tensor(-7.3859),\n",
       "   tensor(-8.9431),\n",
       "   tensor(-10.4693),\n",
       "   tensor(-12.2185),\n",
       "   tensor(-10.8086),\n",
       "   tensor(-9.2889),\n",
       "   tensor(-7.7244),\n",
       "   tensor(-6.3809),\n",
       "   tensor(-5.3799),\n",
       "   tensor(-4.6202),\n",
       "   tensor(-4.0830),\n",
       "   tensor(-3.6816),\n",
       "   tensor(-3.5906),\n",
       "   tensor(-3.7971),\n",
       "   tensor(-4.2322),\n",
       "   tensor(-4.9152),\n",
       "   tensor(-5.8095),\n",
       "   tensor(-6.9026),\n",
       "   tensor(-8.1177),\n",
       "   tensor(-9.4841),\n",
       "   tensor(-11.1371),\n",
       "   tensor(-11.1587),\n",
       "   tensor(-9.8352),\n",
       "   tensor(-8.5093),\n",
       "   tensor(-7.4511),\n",
       "   tensor(-6.3095),\n",
       "   tensor(-5.3387),\n",
       "   tensor(-4.4147),\n",
       "   tensor(-3.9090),\n",
       "   tensor(-3.5778),\n",
       "   tensor(-3.5339),\n",
       "   tensor(-3.7899)],\n",
       "  [tensor(-0.5194),\n",
       "   tensor(-0.6048),\n",
       "   tensor(-0.7595),\n",
       "   tensor(-0.9709),\n",
       "   tensor(-1.3739),\n",
       "   tensor(-1.8763),\n",
       "   tensor(-2.6452),\n",
       "   tensor(-3.6053),\n",
       "   tensor(-4.9073),\n",
       "   tensor(-6.5599),\n",
       "   tensor(-8.4995),\n",
       "   tensor(-10.7322),\n",
       "   tensor(-13.5696),\n",
       "   tensor(-14.3785),\n",
       "   tensor(-12.1569),\n",
       "   tensor(-10.0296),\n",
       "   tensor(-7.6511),\n",
       "   tensor(-5.7756),\n",
       "   tensor(-4.2862),\n",
       "   tensor(-3.3046),\n",
       "   tensor(-2.2360),\n",
       "   tensor(-1.5586),\n",
       "   tensor(-1.2269),\n",
       "   tensor(-0.9164),\n",
       "   tensor(-0.7511),\n",
       "   tensor(-0.6749),\n",
       "   tensor(-0.7723),\n",
       "   tensor(-1.0590),\n",
       "   tensor(-1.5282),\n",
       "   tensor(-2.3088),\n",
       "   tensor(-3.1229),\n",
       "   tensor(-4.3240),\n",
       "   tensor(-5.9814),\n",
       "   tensor(-7.6056),\n",
       "   tensor(-10.0318),\n",
       "   tensor(-12.1289),\n",
       "   tensor(-14.8706),\n",
       "   tensor(-13.0877),\n",
       "   tensor(-10.7156),\n",
       "   tensor(-8.7263),\n",
       "   tensor(-6.7456),\n",
       "   tensor(-5.3221),\n",
       "   tensor(-3.9170),\n",
       "   tensor(-2.7216),\n",
       "   tensor(-1.9414),\n",
       "   tensor(-1.3321),\n",
       "   tensor(-0.9936),\n",
       "   tensor(-0.6867),\n",
       "   tensor(-0.5363),\n",
       "   tensor(-0.4708),\n",
       "   tensor(-0.4766),\n",
       "   tensor(-0.5902),\n",
       "   tensor(-0.7467),\n",
       "   tensor(-1.0875),\n",
       "   tensor(-1.5145),\n",
       "   tensor(-2.2583),\n",
       "   tensor(-3.4018),\n",
       "   tensor(-4.4397),\n",
       "   tensor(-5.7777),\n",
       "   tensor(-7.7320),\n",
       "   tensor(-9.8084),\n",
       "   tensor(-12.4162),\n",
       "   tensor(-15.1449),\n",
       "   tensor(-13.1213),\n",
       "   tensor(-10.9941),\n",
       "   tensor(-8.7289),\n",
       "   tensor(-6.6818),\n",
       "   tensor(-4.9762),\n",
       "   tensor(-3.6149),\n",
       "   tensor(-2.6418),\n",
       "   tensor(-1.9375),\n",
       "   tensor(-1.3510),\n",
       "   tensor(-0.9466),\n",
       "   tensor(-0.6916),\n",
       "   tensor(-0.5960),\n",
       "   tensor(-0.5758),\n",
       "   tensor(-0.6283),\n",
       "   tensor(-0.7142),\n",
       "   tensor(-0.9707),\n",
       "   tensor(-1.3702),\n",
       "   tensor(-1.8841),\n",
       "   tensor(-2.7093),\n",
       "   tensor(-3.7095),\n",
       "   tensor(-4.8739),\n",
       "   tensor(-6.3242),\n",
       "   tensor(-8.4278),\n",
       "   tensor(-11.1606),\n",
       "   tensor(-13.7384),\n",
       "   tensor(-14.1321),\n",
       "   tensor(-12.2931),\n",
       "   tensor(-9.9885),\n",
       "   tensor(-7.8317),\n",
       "   tensor(-5.8942),\n",
       "   tensor(-4.4501),\n",
       "   tensor(-3.4297),\n",
       "   tensor(-2.4375),\n",
       "   tensor(-1.7191),\n",
       "   tensor(-1.1235),\n",
       "   tensor(-0.7402),\n",
       "   tensor(-0.5703),\n",
       "   tensor(-0.4198),\n",
       "   tensor(-0.3045),\n",
       "   tensor(-0.2659),\n",
       "   tensor(-0.2614),\n",
       "   tensor(-0.3250),\n",
       "   tensor(-0.4979),\n",
       "   tensor(-0.7320),\n",
       "   tensor(-1.0271),\n",
       "   tensor(-1.5856),\n",
       "   tensor(-2.2718),\n",
       "   tensor(-3.3722),\n",
       "   tensor(-4.6658),\n",
       "   tensor(-6.2320),\n",
       "   tensor(-8.0850),\n",
       "   tensor(-10.9051),\n",
       "   tensor(-13.3582),\n",
       "   tensor(-15.2842),\n",
       "   tensor(-12.9380),\n",
       "   tensor(-10.6745),\n",
       "   tensor(-8.4556),\n",
       "   tensor(-6.4837),\n",
       "   tensor(-4.6012),\n",
       "   tensor(-3.3399),\n",
       "   tensor(-2.5368),\n",
       "   tensor(-1.7071),\n",
       "   tensor(-1.2276),\n",
       "   tensor(-0.8674),\n",
       "   tensor(-0.6296),\n",
       "   tensor(-0.4779),\n",
       "   tensor(-0.3632),\n",
       "   tensor(-0.2944),\n",
       "   tensor(-0.2924),\n",
       "   tensor(-0.3276),\n",
       "   tensor(-0.4070),\n",
       "   tensor(-0.5884),\n",
       "   tensor(-0.8980),\n",
       "   tensor(-1.2370),\n",
       "   tensor(-1.8108),\n",
       "   tensor(-2.5406),\n",
       "   tensor(-3.3771),\n",
       "   tensor(-4.6503),\n",
       "   tensor(-6.4676),\n",
       "   tensor(-8.4322),\n",
       "   tensor(-10.7422),\n",
       "   tensor(-13.2852),\n",
       "   tensor(-14.6175),\n",
       "   tensor(-12.4206),\n",
       "   tensor(-9.9064),\n",
       "   tensor(-7.7269),\n",
       "   tensor(-5.7910),\n",
       "   tensor(-4.2798),\n",
       "   tensor(-3.0902),\n",
       "   tensor(-2.3182),\n",
       "   tensor(-1.9155),\n",
       "   tensor(-1.6790),\n",
       "   tensor(-1.6184),\n",
       "   tensor(-1.6823),\n",
       "   tensor(-1.9148),\n",
       "   tensor(-2.3808),\n",
       "   tensor(-3.0601),\n",
       "   tensor(-3.8646),\n",
       "   tensor(-4.8890),\n",
       "   tensor(-6.3251),\n",
       "   tensor(-8.0424),\n",
       "   tensor(-10.1138),\n",
       "   tensor(-12.3357),\n",
       "   tensor(-12.9614),\n",
       "   tensor(-10.8479),\n",
       "   tensor(-9.2074),\n",
       "   tensor(-7.4972),\n",
       "   tensor(-5.8774),\n",
       "   tensor(-4.7167),\n",
       "   tensor(-3.6050),\n",
       "   tensor(-2.8885),\n",
       "   tensor(-2.4224),\n",
       "   tensor(-2.1298),\n",
       "   tensor(-2.0195),\n",
       "   tensor(-2.0703),\n",
       "   tensor(-2.4176),\n",
       "   tensor(-2.9043),\n",
       "   tensor(-3.7208),\n",
       "   tensor(-4.9369),\n",
       "   tensor(-6.3616),\n",
       "   tensor(-8.0344),\n",
       "   tensor(-9.5383),\n",
       "   tensor(-11.5998),\n",
       "   tensor(-12.7582),\n",
       "   tensor(-11.0270),\n",
       "   tensor(-9.3754),\n",
       "   tensor(-7.5890),\n",
       "   tensor(-6.0811),\n",
       "   tensor(-4.9056),\n",
       "   tensor(-4.0203),\n",
       "   tensor(-3.3272),\n",
       "   tensor(-2.8634),\n",
       "   tensor(-2.4913),\n",
       "   tensor(-2.4766),\n",
       "   tensor(-2.7446),\n",
       "   tensor(-3.1853),\n",
       "   tensor(-3.8658)]],\n",
       " [201, 201, 201, 201, 201])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rollout(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737258b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026a3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874115ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b8498335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6771a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim): # got in_dim hint\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, 64) # got nn.Linear hint\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.layer3 = nn.Linear(64, out_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x)) # NOT nn.ReLU - which is the actual layer\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7a880b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testNN = FeedForwardNN(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d6083b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testNN(torch.tensor([1,2,3,4,5]).to(torch.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
